{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Bagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setting up\n",
    "\n",
    "- Wine data\n",
    "- Binary classification (filter class 0 and 1)\n",
    "- 2 features ('alcohol','malic_acid')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load data\n",
    "dataObj = load_wine()\n",
    "X = dataObj.data\n",
    "y = dataObj.target\n",
    "\n",
    "# Create DataFrame with features\n",
    "dfori = pd.DataFrame(X)\n",
    "dfori.columns = dataObj.feature_names\n",
    "\n",
    "# Add class column\n",
    "dfori.insert(loc=0, column=\"Class\", value=y)\n",
    "\n",
    "dfori['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter class 0 and 1\n",
    "filt = (dfori['Class'] == 0) | (dfori['Class'] == 1)\n",
    "df = dfori.loc[filt]\n",
    "display(df.head())\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract two features \n",
    "X = df[['alcohol','malic_acid']].values\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1, stratify=y)"
   ]
  },
  {
   "source": [
    "## Dicision tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=1)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "\n",
    "y_test_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score ,recall_score, f1_score\n",
    "\n",
    "def calc_score(y_true, y_pred):\n",
    "    ACC = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    PRE = precision_score(y_true=y_true, y_pred=y_pred, zero_division=1)\n",
    "    REC = recall_score(y_true=y_true, y_pred=y_pred, zero_division=1)\n",
    "    F1 = f1_score(y_true=y_true, y_pred=y_pred, zero_division=1)\n",
    "    # print(f\"ACC:{ACC:6.3f} PRE:{PRE:6.3f} REC:{REC:6.3f} F1:{REC:6.3f}\")\n",
    "    return (ACC, PRE, REC, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "\n",
    "names = ['tree (train)', 'tree (test)']\n",
    "y_trues = [y_train, y_test]\n",
    "y_preds = [y_train_pred, y_test_pred]\n",
    "\n",
    "for y_true, y_pred, name in zip(y_trues, y_preds, names):\n",
    "\n",
    "    ACC, PRE, REC, F1 = calc_score(y_true, y_pred)\n",
    "    data = {'clf': name,\n",
    "            'ACC': f\"{ACC:6.3f}\" ,\n",
    "            'PRE': f\"{PRE:6.3f}\" ,\n",
    "            'REC': f\"{REC:6.3f}\" ,\n",
    "            'F1': f\"{F1:6.3f}\"}\n",
    "    df1 = df1.append(data, ignore_index=True)\n",
    "    \n",
    "df1 = df1.set_index([\"clf\"])\n",
    "display(df1)"
   ]
  },
  {
   "source": [
    "## Decision tree with bagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=1)\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=base,\n",
    "                        n_estimators=500, \n",
    "                        max_samples=1.0, #This results in the same number of observations as the original data.\n",
    "                        max_features=1.0, #Use the same number of features as the original data.\n",
    "                        bootstrap=True, #Sample are drawn with replacement.\n",
    "                        bootstrap_features=False, #Feature are drawn without replcaement.\n",
    "                        n_jobs=1, \n",
    "                        random_state=1)\n",
    "\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = bag.predict(X_train)\n",
    "\n",
    "y_test_pred = bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "\n",
    "names = ['bag (train)', 'bag (test)']\n",
    "y_trues = [y_train, y_test]\n",
    "y_preds = [y_train_pred, y_test_pred]\n",
    "\n",
    "for y_true, y_pred, name in zip(y_trues, y_preds, names):\n",
    "\n",
    "    ACC, PRE, REC, F1 = calc_score(y_true, y_pred)\n",
    "    data = {'clf': name,\n",
    "            'ACC': f\"{ACC:6.3f}\" ,\n",
    "            'PRE': f\"{PRE:6.3f}\" ,\n",
    "            'REC': f\"{REC:6.3f}\" ,\n",
    "            'F1': f\"{F1:6.3f}\"}\n",
    "    df2 = df2.append(data, ignore_index=True)\n",
    "    \n",
    "df2 = df2.set_index([\"clf\"])\n",
    "dfclf = pd.concat((df1,df2))\n",
    "display(dfclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clf = [tree, bag]\n",
    "clf_labels = [\"Tree\", \"Bagging\"]\n",
    "\n",
    "x_min = X[:, 0].min() - 1\n",
    "x_max = X[:, 0].max() + 1\n",
    "y_min = X[:, 1].min() - 1\n",
    "y_max = X[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "f, axarr = plt.subplots(nrows=1, ncols=2, sharex='col', sharey='row', figsize=(10, 5))\n",
    "\n",
    "for ax, clf, tt in zip(axarr, all_clf, clf_labels):\n",
    "\n",
    "    clf.fit(X_train, y_train)    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "    \n",
    "    ax.scatter(X_test[y_test==0, 0], \n",
    "                X_test[y_test==0, 1], \n",
    "                c='blue', \n",
    "                marker='^',\n",
    "                s=50)\n",
    "    \n",
    "    ax.scatter(X_test[y_test==1, 0], \n",
    "                X_test[y_test==1, 1], \n",
    "                c='red', \n",
    "                marker='o',\n",
    "                s=50)\n",
    "    \n",
    "    ax.set_title(tt)\n",
    "    ax.set_xlabel(\"Alcohol\")\n",
    "    ax.set_ylabel(\"malic_acid\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  }
 ]
}